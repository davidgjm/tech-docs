<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.23">
<title>Queue-Based Load Leveling pattern</title>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/darshandsoni/asciidoctor-skins/css/material-teal.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>Queue-Based Load Leveling pattern</h1>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_context_and_problem">Context and problem</a></li>
<li><a href="#_solution">Solution</a></li>
<li><a href="#_issues_and_considerations">Issues and considerations</a></li>
<li><a href="#_when_to_use_this_pattern">When to use this pattern</a></li>
<li><a href="#_example">Example</a></li>
<li><a href="#_next_steps">Next steps</a></li>
<li><a href="#_related_guidance">Related guidance</a></li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Use a queue that acts as a buffer between a task and a service it invokes in order to smooth intermittent heavy loads that can cause the service to fail or the task to time out. This can help to minimize the impact of peaks in demand on availability and responsiveness for both the task and the service.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_context_and_problem">Context and problem</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Many solutions in the cloud involve running tasks that invoke services. In this environment, if a service is subjected to intermittent heavy loads, it can cause performance or reliability issues.</p>
</div>
<div class="paragraph">
<p>A service could be part of the same solution as the tasks that use it, or it could be a third-party service providing access to frequently used resources such as a cache or a storage service. If the same service is used by a number of tasks running concurrently, it can be difficult to predict the volume of requests to the service at any time.</p>
</div>
<div class="paragraph">
<p>A service might experience peaks in demand that cause it to overload and be unable to respond to requests in a timely manner. Flooding a service with a large number of concurrent requests can also result in the service failing if it&#8217;s unable to handle the contention these requests cause.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_solution">Solution</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Refactor the solution and introduce a queue between the task and the service. The task and the service run asynchronously. The task posts a message containing the data required by the service to a queue. The queue acts as a buffer, storing the message until it&#8217;s retrieved by the service. The service retrieves the messages from the queue and processes them. Requests from a number of tasks, which can be generated at a highly variable rate, can be passed to the service through the same message queue. This figure shows using a queue to level the load on a service.</p>
</div>
<div id="img-load-leveling" class="imageblock">
<div class="content">
<img src="./images/queue-based-load-leveling-pattern.png" alt="queue based load leveling pattern">
</div>
<div class="title">Figure 1. Solution - using a queue for load leveling</div>
</div>
<div class="paragraph">
<p>The queue decouples the tasks from the service, and the service can handle the messages at its own pace regardless of the volume of requests from concurrent tasks. Additionally, there&#8217;s no delay to a task if the service isn&#8217;t available at the time it posts a message to the queue.</p>
</div>
<div class="paragraph">
<p>This pattern provides the following benefits:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>It can help to maximize availability because delays arising in services won&#8217;t have an immediate and direct impact on the application, which can continue to post messages to the queue even when the service isn&#8217;t available or isn&#8217;t currently processing messages.</p>
</li>
<li>
<p>It can help to maximize scalability because both the number of queues and the number of services can be varied to meet demand.</p>
</li>
<li>
<p>It can help to control costs because the number of service instances deployed only have to be adequate to meet average load rather than the peak load.</p>
</li>
</ul>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Some services implement throttling when demand reaches a threshold beyond which the system could fail. Throttling can reduce the functionality available. You can implement load leveling with these services to ensure that this threshold isn&#8217;t reached.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_issues_and_considerations">Issues and considerations</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Consider the following points when deciding how to implement this pattern:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>It&#8217;s necessary to implement application logic that controls the rate at which services handle messages to avoid overwhelming the target resource. <mark>Avoid passing spikes in demand to the next stage of the system.</mark> Test the system under load to ensure that it provides the required leveling, and adjust the number of queues and the number of service instances that handle messages to achieve this.</p>
</li>
<li>
<p>Message queues are a one-way communication mechanism. If a task expects a reply from a service, it might be necessary to implement a mechanism that the service can use to send a response. For more information, see the <a href="../distributed-systems/messaging/async-messaging/async-messaging-primer.html">Asynchronous Messaging Primer</a>.</p>
</li>
<li>
<p>Be careful if you apply autoscaling to services that are listening for requests on the queue. This can result in increased contention for any resources that these services share and diminish the effectiveness of using the queue to level the load.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_when_to_use_this_pattern">When to use this pattern</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This pattern is useful to any application that uses services that are subject to overloading.</p>
</div>
<div class="paragraph">
<p>This pattern isn&#8217;t useful if the application expects a response from the service with minimal latency.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_example">Example</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A web app writes data to an external data store. If a large number of instances of the web app run concurrently, the data store might be unable to respond to requests quickly enough, causing requests to time out, be throttled, or otherwise fail. The following diagram shows a data store being overwhelmed by a large number of concurrent requests from instances of an application.</p>
</div>
<div id="img_overwhelmed" class="imageblock">
<div class="content">
<img src="./images/queue-based-load-leveling-overwhelmed.png" alt="queue based load leveling overwhelmed">
</div>
<div class="title">Figure 2. A service being overwhelmed by a large number of concurrent requests from instances of a web app</div>
</div>
<div class="paragraph">
<p>To resolve this, you can use a queue to level the load between the application instances and the data store. An Azure Functions app reads the messages from the queue and performs the read/write requests to the data store. The application logic in the function app can control the rate at which it passes requests to the data store, to prevent the store from being overwhelmed. (Otherwise the function app will just re-introduce the same problem at the back end.)</p>
</div>
<div id="img-functionapp" class="imageblock">
<div class="content">
<img src="./images/queue-based-load-leveling-function.png" alt="queue based load leveling function">
</div>
<div class="title">Figure 3. solution with function app</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_next_steps">Next steps</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The following guidance might also be relevant when implementing this pattern:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="../distributed-systems/messaging/async-messaging/async-messaging-primer.html">Asynchronous Messaging Primer</a>. Message queues are inherently asynchronous. It might be necessary to redesign the application logic in a task if it&#8217;s adapted from communicating directly with a service to using a message queue. Similarly, it might be necessary to refactor a service to accept requests from a message queue. Alternatively, it might be possible to implement a proxy service, as described in the example.</p>
</li>
<li>
<p><a href="https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services">Choose between Azure messaging services</a>. Information about choosing a messaging and queuing mechanism in Azure applications.</p>
</li>
<li>
<p><a href="https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/app-service-web-app/scalable-web-app">Improve scalability in an Azure web application</a>. This reference architecture includes queue-based load leveling as part of the architecture.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_related_guidance">Related guidance</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The following patterns might also be relevant when implementing this pattern:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="competing-consumers.html">Competing Consumers pattern</a>. It might be possible to run multiple instances of a service, each acting as a message consumer from the load-leveling queue. You can use this approach to adjust the rate at which messages are received and passed to a service.</p>
</li>
<li>
<p><a href="throttling.html">Throttling pattern</a>. A simple way to implement throttling with a service is to use queue-based load leveling and route all requests to a service through a message queue. The service can process requests at a rate that ensures that resources required by the service aren&#8217;t exhausted, and to reduce the amount of contention that could occur.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2025-06-22 13:10:08 UTC
</div>
</div>
</body>
</html>