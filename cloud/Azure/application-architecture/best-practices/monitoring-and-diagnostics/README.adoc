= Monitoring and diagnostics
:toc:
:source-highlighter: rouge
:icons: font
:tip-caption: ðŸ’¡
:imagesdir: ./images

ifdef::env-github[]
:tip-caption: :bulb:
endif::[]

.References
[sidebar]
****
* https://docs.microsoft.com/en-us/azure/architecture/best-practices/monitoring[Best practices for monitoring cloud applications]
****



.Reflections
[TIP]
=====
* How can this be implemented with Spring Boot Actuator endpoints?
* Which Actuator endpoints correspond to:
- health monitoring
- availability monitoring
=====


== Monitoring and diagnostics scenarios

icon:android[]

You can use monitoring to gain an insight into how well a system is functioning. Monitoring is a crucial part of maintaining quality-of-service targets. Common scenarios for collecting monitoring data include:

* Ensuring that the system remains healthy.
* Tracking the availability of the system and its component elements.
* Maintaining performance to ensure that the throughput of the system does not degrade unexpectedly as the volume of work increases.
* Guaranteeing that the system meets any service-level agreements (SLAs) established with customers.
* Protecting the privacy and security of the system, users, and their data.
* Tracking the operations that are performed for auditing or regulatory purposes.
* Monitoring the day-to-day usage of the system and spotting trends that might lead to problems if they're not addressed.
* Tracking issues that occur, from initial report through to analysis of possible causes, rectification, consequent software updates, and deployment.
* Tracing operations and debugging software releases.

NOTE: This list is not intended to be comprehensive. This document focuses on these scenarios as the most common situations for performing monitoring. There might be others that are less common or are specific to your environment.




ifdef::safe-mode-unsafe[]
include::health-monitoring.adoc[leveloffset=+1]

include::availability-monitoring.adoc[leveloffset=+1]

include::performance-monitoring.adoc[leveloffset=+1]

include::security-monitoring.adoc[leveloffset=+1]

include::sla-monitoring.adoc[leveloffset=+1]

include::auditing.adoc[leveloffset=+1]

endif::safe-mode-unsafe[]


// Github uses secure mode by default
ifdef::safe-mode-secure[]

xref:health-monitoring.adoc[Health Monitoring]

xref:availability-monitoring.adoc[Availability Monitoring]

xref:performance-monitoring.adoc[Performance Monitoring]

xref:security-monitoring.adoc[Security Monitoring]

xref:sla-monitoring.adoc[SLA Monitoring]

xref:auditing.adoc[Auditing]

endif::safe-mode-secure[]

== The monitoring and diagnostics pipeline

Monitoring a large-scale distributed system poses a significant challenge. Each of the scenarios described in the previous section should not necessarily be considered in isolation. There is likely to be a significant overlap in the monitoring and diagnostic data that's required for each situation, although this data might need to be processed and presented in different ways. For these reasons, you should take a holistic view of monitoring and diagnostics.

You can envisage the entire monitoring and diagnostics process as a pipeline that comprises the stages shown in Figure 1.

[#img-pipeline]
.The stages in the monitoring and diagnostics pipeline
image::pipeline.png[The stages in the monitoring and diagnostics pipeline.]


Figure 1 highlights how the data for monitoring and diagnostics can come from a variety of data sources. The instrumentation and collection stages are concerned with identifying the sources from where the data needs to be captured, determining which data to capture, how to capture it, and how to format this data so that it can be easily examined. The analysis/diagnosis stage takes the raw data and uses it to generate meaningful information that an operator can use to determine the state of the system. The operator can use this information to make decisions about possible actions to take, and then feed the results back into the instrumentation and collection stages. The visualization/alerting stage phase presents a consumable view of the system state. It can display information in near real time by using a series of dashboards. And it can generate reports, graphs, and charts to provide a historical view of the data that can help identify long-term trends. If information indicates that a KPI is likely to exceed acceptable bounds, this stage can also trigger an alert to an operator. In some cases, an alert can also be used to trigger an automated process that attempts to take corrective actions, such as autoscaling.

Note that these steps constitute a continuous-flow process where the stages are happening in parallel. Ideally, all the phases should be dynamically configurable. At some points, especially when a system has been newly deployed or is experiencing problems, it might be necessary to gather extended data on a more frequent basis. At other times, it should be possible to revert to capturing a base level of essential information to verify that the system is functioning properly.

Additionally, the entire monitoring process should be considered a live, ongoing solution that's subject to fine-tuning and improvements as a result of feedback. For example, you might start with measuring many factors to determine system health. Analysis over time might lead to a refinement as you discard measures that aren't relevant, enabling you to more precisely focus on the data that you need while minimizing background noise.

== Sources of monitoring and diagnostic data

The information that the monitoring process uses can come from several sources, as illustrated in Figure 1. At the application level, information comes from trace logs incorporated into the code of the system. Developers should follow a standard approach for tracking the flow of control through their code. For example, an entry to a method can emit a trace message that specifies the name of the method, the current time, the value of each parameter, and any other pertinent information. Recording the entry and exit times can also prove useful.

You should log all exceptions and warnings, and ensure that you retain a full trace of any nested exceptions and warnings. Ideally, you should also capture information that identifies the user who is running the code, together with activity correlation information (to track requests as they pass through the system). And you should log attempts to access all resources such as message queues, databases, files, and other dependent services. This information can be used for metering and auditing purposes.

Many applications use libraries and frameworks to perform common tasks such as accessing a data store or communicating over a network. These frameworks might be configurable to provide their own trace messages and raw diagnostic information, such as transaction rates and data transmission successes and failures.

NOTE: Many modern frameworks automatically publish performance and trace events. Capturing this information is simply a matter of providing a means to retrieve and store it where it can be processed and analyzed.

The operating system where the application is running can be a source of low-level system-wide information, such as performance counters that indicate I/O rates, memory utilization, and CPU usage. Operating system errors (such as the failure to open a file correctly) might also be reported.

You should also consider the underlying infrastructure and components on which your system runs. Virtual machines, virtual networks, and storage services can all be sources of important infrastructure-level performance counters and other diagnostic data.

If your application uses other external services, such as a web server or database management system, these services might publish their own trace information, logs, and performance counters. Examples include SQL Server Dynamic Management Views for tracking operations performed against a SQL Server database, and IIS trace logs for recording requests made to a web server.

As the components of a system are modified and new versions are deployed, it's important to be able to attribute issues, events, and metrics to each version. This information should be tied back to the release pipeline so that problems with a specific version of a component can be tracked quickly and rectified.

Security issues might occur at any point in the system. For example, a user might attempt to sign in with an invalid user ID or password. An authenticated user might try to obtain unauthorized access to a resource. Or a user might provide an invalid or outdated key to access encrypted information. Security-related information for successful and failing requests should always be logged.

The section xref:instrumenting-application.adoc[Instrumenting an application] contains more guidance on the information that you should capture. But you can use a variety of strategies to gather this information:

[unordered]
Application/system monitoring.:: This strategy uses internal sources within the application, application frameworks, operating system, and infrastructure. The application code can generate its own monitoring data at notable points during the lifecycle of a client request. The application can include tracing statements that might be selectively enabled or disabled as circumstances dictate. It might also be possible to inject diagnostics dynamically by using a diagnostics framework. These frameworks typically provide plug-ins that can attach to various instrumentation points in your code and capture trace data at these points.

Additionally, your code and/or the underlying infrastructure might raise events at critical points. Monitoring agents that are configured to listen for these events can record the event information.

Real user monitoring.:: This approach records the interactions between a user and the application and observes the flow of each request and response. This information can have a two-fold purpose: it can be used for metering usage by each user, and it can be used to determine whether users are receiving a suitable quality of service (for example, fast response times, low latency, and minimal errors). You can use the captured data to identify areas of concern where failures occur most often. You can also use the data to identify elements where the system slows down, possibly due to hotspots in the application or some other form of bottleneck. If you implement this approach carefully, it might be possible to reconstruct users' flows through the application for debugging and testing purposes.

[IMPORTANT]
====
You should consider the data that's captured by monitoring real users to be highly sensitive because it might include confidential material. If you save captured data, store it securely. If you want to use the data for performance monitoring or debugging purposes, strip out all personally identifiable information first.
====

Synthetic user monitoring.:: In this approach, you write your own test client that simulates a user and performs a configurable but typical series of operations. You can track the performance of the test client to help determine the state of the system. You can also use multiple instances of the test client as part of a load-testing operation to establish how the system responds under stress, and what sort of monitoring output is generated under these conditions.

NOTE: You can implement real and synthetic user monitoring by including code that traces and times the execution of method calls and other critical parts of an application.

Profiling.:: This approach is primarily targeted at monitoring and improving application performance. Rather than operating at the functional level of real and synthetic user monitoring, it captures lower-level information as the application runs. You can implement profiling by using periodic sampling of the execution state of an application (determining which piece of code that the application is running at a given point in time). You can also use instrumentation that inserts probes into the code at important junctures (such as the start and end of a method call) and records which methods were invoked, at what time, and how long each call took. You can then analyze this data to determine which parts of the application might cause performance problems.

Endpoint monitoring.:: This technique uses one or more diagnostic endpoints that the application exposes specifically to enable monitoring. An endpoint provides a pathway into the application code and can return information about the health of the system. Different endpoints can focus on various aspects of the functionality. You can write your own diagnostics client that sends periodic requests to these endpoints and assimilate the responses. For more information, see the https://docs.microsoft.com/en-us/azure/architecture/patterns/health-endpoint-monitoring[Health Endpoint Monitoring pattern].

For maximum coverage, you should use a combination of these techniques.

include::instrumenting-application.adoc[leveloffset=+1]
